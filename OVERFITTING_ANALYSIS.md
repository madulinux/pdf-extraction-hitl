# ğŸ” Analisis Overfitting: Mengapa Metrics 99% tapi Hasil Ekstraksi Buruk?

## ğŸ“Š **Situasi Anda**

```
âœ… Training Metrics: 99% accuracy
âŒ Real Extraction: Hasil buruk/tidak sesuai harapan
```

**Ini adalah classic overfitting problem!**

---

## ğŸš¨ **Root Cause: 3 Masalah Utama**

### **1ï¸âƒ£ Data Leakage - Training & Testing Pakai Data yang Sama**

**Masalah:**
```python
# âŒ WRONG: No train/test split
X_train = all_data  # 100 samples
y_train = all_labels

model.train(X_train, y_train)
metrics = model.evaluate(X_train, y_train)  # âŒ Evaluasi pakai data yang sama!
# Result: 99% accuracy (tapi PALSU!)
```

**Kenapa Palsu?**
- Model sudah "lihat" data saat training
- Evaluasi jadi seperti "ujian dengan soal yang sama"
- Metrics tinggi tapi tidak mencerminkan performa real

**Solusi:**
```python
# âœ… CORRECT: Proper train/test split
X_train, X_test, y_train, y_test = split_training_data(
    all_data, all_labels,
    test_size=0.2  # 80% train, 20% test
)

model.train(X_train, y_train)  # Train pada 80% data
metrics = model.evaluate(X_test, y_test)  # âœ… Evaluasi pada 20% data BARU
# Result: 70% accuracy (tapi REAL!)
```

---

### **2ï¸âƒ£ Low Data Diversity - Data Terlalu Mirip**

**Masalah:**
```python
# Data dari generator dengan pola yang sangat konsisten:
{
    "recipient_name": "Edison Narpati",      # Selalu nama Indonesia
    "event_date": "18 January 2025",         # Selalu format DD Month YYYY
    "event_location": "Gang Rawamangun...",  # Selalu format alamat Indonesia
    "certificate_number": "72/CVC/01/2025"   # Selalu format nomor/kode/bulan/tahun
}

# 100 dokumen dengan pola yang SAMA PERSIS
# Hanya beda nama/tanggal, tapi struktur identik
```

**Akibat:**
- Model belajar **pola generator**, bukan **pola ekstraksi**
- Model "hafal" posisi field di template ini
- Saat coba dokumen baru (beda format), model gagal!

**Diversity Score:**
```
Total samples: 100
Unique sequences: 15  # Hanya 15 variasi dari 100 dokumen!
Diversity score: 15%  # âŒ SANGAT RENDAH!

Threshold:
- < 30%: CRITICAL - Data terlalu mirip
- 30-50%: Low - Perlu lebih banyak variasi
- 50-70%: Moderate - Cukup baik
- > 70%: Good - Data bervariasi
```

**Solusi:**
1. **Variasi template** - Gunakan 3-5 template berbeda
2. **Variasi format** - Ubah layout, font, spacing
3. **Variasi data** - Nama asing, format tanggal berbeda, dll
4. **Real-world data** - Gunakan dokumen asli, bukan hanya generated

---

### **3ï¸âƒ£ Overfitting - Model Memorize, Bukan Learn**

**Masalah:**
```
Training Accuracy: 99%
Test Accuracy: 45%
Gap: 54%  # âŒ OVERFITTING!
```

**Analogi:**
```
Seperti siswa yang hafal soal ujian tahun lalu:
- Nilai ujian lama: 99 (hafal semua jawaban)
- Nilai ujian baru: 45 (tidak paham konsep)
- Gap besar = tidak paham, hanya hafal!
```

**Model Anda:**
- Hafal posisi field di 100 dokumen training
- Tidak belajar cara ekstraksi yang general
- Gagal saat dokumen baru (beda posisi/format)

---

## âœ… **Solusi yang Sudah Diimplementasikan**

### **1. Train/Test Split (80/20)**

```python
# File: backend/core/learning/services.py

# âœ… Split data
X_train_split, X_test_split, y_train_split, y_test_split = split_training_data(
    X_train, y_train,
    test_size=0.2,
    random_state=42
)

# âœ… Train on 80%
metrics = learner.train(X_train_split, y_train_split)

# âœ… Evaluate on 20% (unseen data)
test_metrics = learner.evaluate(X_test_split, y_test_split)

# âœ… Compare
print(f"Training Accuracy: {metrics['accuracy']*100:.2f}%")
print(f"Test Accuracy:     {test_metrics['accuracy']*100:.2f}%")
print(f"Difference:        {abs(metrics['accuracy'] - test_metrics['accuracy'])*100:.2f}%")

if abs(metrics['accuracy'] - test_metrics['accuracy']) > 0.1:
    print("âš ï¸  WARNING: Overfitting detected!")
else:
    print("âœ… Good generalization")
```

### **2. Data Quality Validation**

```python
# âœ… Check diversity
diversity_metrics = validate_training_data_diversity(X_train, y_train)

# Output:
# Total samples: 100
# Unique sequences: 15
# Diversity score: 15%  # âŒ Too low!
# âš ï¸  Low diversity detected. Your training data may be too similar!
```

### **3. Data Leakage Detection**

```python
# âœ… Check for duplicates between train/test
leakage_results = detect_data_leakage(X_train_split, X_test_split)

# Output:
# âš ï¸  Potential data leakage detected!
# Found 5 highly similar samples between train/test
# This may lead to inflated metrics!
```

### **4. Recommendations**

```python
recommendations = get_training_recommendations(
    num_samples=len(X_train),
    diversity_score=diversity_metrics['diversity_score'],
    has_leakage=leakage_results['leakage_detected']
)

# Output:
# âœ… Good dataset size.
# âŒ CRITICAL: Very low diversity. Data is too similar - high overfitting risk!
# âŒ CRITICAL: Data leakage detected! Metrics are inflated. Re-split your data.
# âš ï¸  Training setup needs improvement. Address issues above.
```

---

## ğŸ¯ **Expected Output Setelah Fix**

### **Before (Overfitted):**
```
ğŸ“Š Training Summary:
   Total training samples: 100
   
ğŸ“ Training model...
   Training Accuracy: 99.2%
   
âŒ Real extraction: Buruk (model hafal, tidak paham)
```

### **After (Proper ML):**
```
ğŸ“Š Training Summary:
   Total training samples: 100
   
ğŸ” Validating training data quality...
   Total samples: 100
   Unique sequences: 15
   Diversity score: 15%
   âš ï¸  Low diversity detected!
   
ğŸ“Š Splitting data into train/test sets...
   Total samples: 100
   Training: 80 (80.0%)
   Testing: 20 (20.0%)
   
ğŸ” Checking for data leakage...
   âš ï¸  Potential data leakage detected!
   Found 3 highly similar samples
   
ğŸ’¡ Training Recommendations:
   âœ… Good dataset size.
   âŒ CRITICAL: Very low diversity. Data is too similar!
   âš ï¸  Training setup needs improvement.
   
ğŸ“ Training model on 80 samples...
   Training Accuracy: 98.5%
   
ğŸ“Š Evaluating on 20 test samples...
   Test Accuracy: 72.3%
   
ğŸ“ˆ Results Comparison:
   Training Accuracy: 98.50%
   Test Accuracy:     72.30%
   Difference:        26.20%
   âš ï¸  WARNING: Large gap between train/test accuracy!
       This indicates overfitting. Model memorized training data.
```

**Interpretasi:**
- **Training 98.5%** - Model belajar dengan baik
- **Test 72.3%** - Performa real pada data baru
- **Gap 26.2%** - Ada overfitting, tapi sekarang kita TAHU!
- **72.3% adalah metrics yang REAL**, bukan 99% yang palsu

---

## ğŸš€ **Action Plan untuk Improve**

### **Immediate (Sekarang):**

1. **Re-train dengan split baru:**
   ```bash
   # Training sekarang otomatis pakai train/test split
   curl -X POST http://localhost:8000/api/v1/models/retrain \
     -H "Authorization: Bearer $TOKEN" \
     -d '{"template_id": 1, "use_all_feedback": true}'
   ```

2. **Check metrics yang REAL:**
   ```
   Training Accuracy: ~95-98%
   Test Accuracy: ~70-80%  # Ini yang real!
   ```

### **Short-term (Minggu ini):**

3. **Improve data diversity:**
   ```bash
   # Generate dengan variasi lebih banyak
   # - Ubah template layout
   # - Variasi format data
   # - Tambah noise/variasi
   ```

4. **Add more templates:**
   ```bash
   # Gunakan 3-5 template berbeda
   # Bukan 100 docs dari 1 template
   # Tapi 20-30 docs dari 3-5 templates
   ```

### **Long-term (Untuk BAB 4):**

5. **Use real-world data:**
   - Scan dokumen asli (bukan generated)
   - Variasi kualitas scan
   - Variasi format/layout

6. **Cross-validation:**
   - K-fold CV untuk metrics lebih robust
   - Test pada template yang berbeda

---

## ğŸ“Š **Untuk BAB 4: Realistic Metrics**

### **Honest Reporting:**

```markdown
## 4.2.2 Evaluasi Model CRF

### Training Setup:
- Total data: 100 dokumen
- Training set: 80 dokumen (80%)
- Test set: 20 dokumen (20%)
- Data diversity: 15% (rendah)

### Results:
- Training accuracy: 98.5%
- **Test accuracy: 72.3%** â† Real performance
- Precision: 75.2%
- Recall: 68.9%
- F1-score: 71.9%

### Analysis:
Gap antara training (98.5%) dan test (72.3%) menunjukkan adanya overfitting.
Model cenderung menghafal pola training data dibanding belajar ekstraksi general.
Hal ini disebabkan oleh:
1. Low data diversity (15%)
2. Data generated dengan pola konsisten
3. Semua data dari template yang sama

### Recommendations:
1. Tingkatkan diversity dengan menggunakan multiple templates
2. Tambahkan variasi format dan layout
3. Gunakan real-world documents
```

**Ini lebih jujur dan ilmiah!**

---

## ğŸ“ **Key Takeaways**

1. âœ… **Metrics 99% itu PALSU** - Karena evaluasi pakai data training
2. âœ… **Metrics 70-80% itu REAL** - Evaluasi pakai data test (unseen)
3. âœ… **Gap besar = Overfitting** - Model hafal, tidak paham
4. âœ… **Low diversity = Problem** - Data terlalu mirip
5. âœ… **Honest reporting** - Lebih baik lapor 70% real daripada 99% palsu

---

## ğŸ”§ **Next Steps**

1. **Re-train sekarang** dengan split baru
2. **Check test accuracy** (bukan training accuracy)
3. **Jika test accuracy < 70%**, improve data diversity
4. **Untuk BAB 4**, gunakan test accuracy sebagai metrics utama

**Training yang baik bukan yang metrics-nya tinggi, tapi yang generalize dengan baik!** ğŸ¯
