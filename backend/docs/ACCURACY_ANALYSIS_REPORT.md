# üìä Accuracy Analysis Report: Current Status & Path Forward

**Date:** 2024-11-09  
**Status:** üîÑ IN PROGRESS  
**Current Accuracy:** 18-52% (High Variance)

---

## üìà Current Situation

### Accuracy Timeline
```
Session Start:  6.68% (baseline, broken metadata)
After Fixes:   52.60% (field-aware + safeguards working)
After Bug:     12.12% (missing target_fields parameter)
After Fix:     51.82% (5 docs) ‚Üí 18.18% (20 docs)

Current: HIGH VARIANCE (18-52%)
```

### Training Data
```
Documents: 255 (used for training)
Feedback:  4,447 records
Model:     Template 1 (medical_form_template)
Test Acc:  98.21% (model internal test)
Real Acc:  18-52% (on new documents)
```

---

## üîç Root Cause Analysis

### Issue 1: Model-Reality Gap ‚úÖ IDENTIFIED

**Observation:**
```
Model Test Accuracy: 98.21% (excellent!)
Real Extraction Accuracy: 18-52% (poor!)

Gap: 46-80% difference!
```

**Why This Happens:**

#### A. **Training Data Homogeneity**
```
Training documents (255):
- Generated from same template
- Similar layout patterns
- Consistent field positions
- Limited variation in formatting

Test documents (new):
- Different layout variations
- Field positions vary
- Text formatting differs
- Model hasn't seen these patterns
```

**Evidence:**
```sql
-- Check document diversity
SELECT field_name, COUNT(DISTINCT corrected_value) as unique_values
FROM feedback WHERE used_for_training = 1
GROUP BY field_name;

Results show: Limited value diversity per field
```

---

#### B. **Extraction Strategy Performance**

**Per-Strategy Accuracy (from traces):**
```
CRF Strategy:
- temperature: 90.2% (good!)
- weight: 63.5% (moderate)
- recommendations: 11.5% (poor)
- Overall: Varies by field type

Rule-based Strategy:
- Simple fields: 25-30% (poor)
- Complex fields: 0% (fails)
- Overall: Not robust

Position-based Strategy:
- Depends on layout consistency
- Fails when layout changes
- Overall: Unreliable for varied layouts
```

---

#### C. **Field Type Difficulty**

**Easy Fields (>60% accuracy):**
- `temperature`: 90.2%
- `weight`: 63.5%
- `height`: Similar to weight
- `blood_pressure`: Similar to vitals

**Moderate Fields (30-60% accuracy):**
- `patient_name`: ~40%
- `exam_date`: ~35%
- `patient_age`: ~30%

**Hard Fields (<30% accuracy):**
- `recommendations`: 11.5%
- `diagnosis`: ~15%
- `medical_history`: ~12%
- `prescription`: ~10%

**Pattern:** Text fields (multi-word, variable length) are hardest!

---

### Issue 2: Layout Variation ‚úÖ IDENTIFIED

**Example from Document 295:**
```
Extracted vs Truth:
‚ùå patient_name: "Lahir: 08-01-1992" vs "R. Patricia Mulyani, S.I.Kom"
‚ùå patient_birth_date: "15-09-2025" vs "08-01-1992"
‚ùå patient_age: "Perempuan" vs "33"
‚ùå patient_gender: "Jalan Gedebage..." vs "Perempuan"

Problem: Model extracting WRONG field values (positional confusion)
```

**Why:**
- Training data has consistent layout
- New documents have different layouts
- Model learned position-based patterns
- Patterns don't generalize to new layouts

---

### Issue 3: High Variance ‚úÖ IDENTIFIED

**Observation:**
```
Test 1 (5 docs):  51.82% accuracy
Test 2 (20 docs): 18.18% accuracy

Variance: 33.64% difference!
```

**Causes:**
1. **Small sample size** (5 vs 20 docs)
2. **Layout variation** (some docs match training, some don't)
3. **Field difficulty mix** (easy vs hard fields ratio varies)
4. **Random generation** (faker library creates varied data)

---

## üéØ Path Forward: Action Plan

### Priority 1: Increase Training Data Diversity üî¥ CRITICAL

**Goal:** Train model on MORE VARIED layouts

**Actions:**
1. ‚úÖ Generate 100+ documents with VARIED layouts
2. ‚úÖ Ensure field positions vary across documents
3. ‚úÖ Include edge cases (long text, special chars, etc.)
4. ‚úÖ Validate and correct all generated documents
5. ‚úÖ Retrain model with expanded dataset

**Expected Impact:** +20-30% accuracy improvement

---

### Priority 2: Improve Text Field Extraction üü° HIGH

**Goal:** Better handle multi-word, variable-length fields

**Current Performance:**
- `recommendations`: 11.5%
- `diagnosis`: ~15%
- `medical_history`: ~12%

**Actions:**
1. ‚úÖ Add boundary detection features
2. ‚úÖ Improve multi-line text handling
3. ‚úÖ Add context-aware features (nearby labels)
4. ‚úÖ Train with more text field examples

**Expected Impact:** +15-20% accuracy for text fields

---

### Priority 3: Enhance Feature Engineering üü° HIGH

**Goal:** Add features that generalize better

**Current Features:**
- Lexical (word form, case, digits)
- Orthographic (capitalization)
- Layout (position on page) ‚Üê TOO SPECIFIC!
- Field-aware (target field indicator)

**New Features to Add:**
1. ‚úÖ **Semantic features** (word embeddings)
2. ‚úÖ **Contextual features** (nearby label text)
3. ‚úÖ **Relative position** (instead of absolute)
4. ‚úÖ **Field boundary indicators** (start/end markers)
5. ‚úÖ **Pattern matching** (regex-based validation)

**Expected Impact:** +10-15% accuracy improvement

---

### Priority 4: Strategy Selection Optimization üü¢ MEDIUM

**Goal:** Better choose which strategy to use per field

**Current Logic:**
```python
# Adaptive selection based on historical performance
if crf_confidence > threshold and crf_accuracy > rule_accuracy:
    use CRF
else:
    use rule_based
```

**Issues:**
- Threshold too conservative
- Doesn't consider field type
- Doesn't handle "no result" cases well

**Improvements:**
1. ‚úÖ Field-type specific thresholds
2. ‚úÖ Confidence calibration
3. ‚úÖ Fallback strategy chain
4. ‚úÖ Ensemble methods (combine strategies)

**Expected Impact:** +5-10% accuracy improvement

---

### Priority 5: Post-Processing & Validation üü¢ MEDIUM

**Goal:** Clean and validate extracted values

**Current:** No post-processing

**Add:**
1. ‚úÖ **Pattern validation** (e.g., dates must match DD-MM-YYYY)
2. ‚úÖ **Length validation** (e.g., phone must be 10-15 digits)
3. ‚úÖ **Boundary cleaning** (remove label text from values)
4. ‚úÖ **Confidence adjustment** (lower if validation fails)

**Expected Impact:** +5-10% accuracy improvement

---

## üìä Expected Results

### Cumulative Impact
```
Current:        18-52% (avg ~35%)
+ Diversity:    +25% ‚Üí 60%
+ Text Fields:  +15% ‚Üí 75%
+ Features:     +10% ‚Üí 85%
+ Strategy:     +5%  ‚Üí 90%
+ Validation:   +5%  ‚Üí 95%

Target:         90-95% accuracy
Realistic:      75-85% accuracy (conservative estimate)
```

### Timeline
```
Week 1: Generate & validate 100+ diverse documents
Week 2: Implement new features & retrain
Week 3: Optimize strategy selection
Week 4: Add post-processing & validation
Week 5: Test & iterate

Total: 5 weeks to 75-85% accuracy
```

---

## üî¨ Detailed Recommendations

### 1. Data Generation Strategy

**Current Problem:**
```python
# Faker generates random data
# Layout is consistent (same template)
# Limited variation in field positions
```

**Solution:**
```python
# Generate with CONTROLLED variation:
1. Create 5-10 layout variants
2. For each variant:
   - Vary field positions (¬±10-20 pixels)
   - Vary text length (short/medium/long)
   - Vary formatting (bold/normal, size)
3. Generate 20 docs per variant
4. Total: 100-200 documents with real variation
```

---

### 2. Feature Engineering Details

#### A. **Semantic Features**
```python
# Add word embeddings (e.g., Word2Vec, FastText)
word_features['word_embedding'] = get_embedding(word_text)
word_features['embedding_similarity_to_label'] = cosine_sim(
    word_embedding, label_embedding
)
```

#### B. **Contextual Features**
```python
# Look for nearby label text
nearby_labels = find_labels_near_word(word, radius=50)
word_features['has_label_left'] = 'Nama:' in nearby_labels['left']
word_features['has_label_above'] = 'Tanggal:' in nearby_labels['above']
```

#### C. **Relative Position**
```python
# Instead of absolute (x, y):
word_features['relative_x'] = word['x0'] / page_width
word_features['relative_y'] = word['y0'] / page_height
word_features['quadrant'] = get_quadrant(relative_x, relative_y)
```

---

### 3. Text Field Handling

**Problem:** Multi-word fields hard to extract

**Solution:**
```python
# A. Better boundary detection
def find_field_boundaries(words, field_name, context):
    # Look for label text
    label_pos = find_label(words, field_name)
    
    # Extract until next label or boundary
    start_idx = label_pos + 1
    end_idx = find_next_label(words, start_idx) or len(words)
    
    return words[start_idx:end_idx]

# B. Multi-line support
def extract_multiline_field(words, field_name):
    # Group words by line (y-coordinate)
    lines = group_by_line(words)
    
    # Extract consecutive lines
    field_lines = []
    in_field = False
    for line in lines:
        if has_field_label(line, field_name):
            in_field = True
        elif in_field and has_next_label(line):
            break
        elif in_field:
            field_lines.append(line)
    
    return ' '.join(field_lines)
```

---

### 4. Strategy Selection Logic

**Current:**
```python
# Simple threshold-based
if crf_confidence > 0.7:
    return crf_result
else:
    return rule_result
```

**Improved:**
```python
# Field-type aware
THRESHOLDS = {
    'simple': 0.6,   # name, age, date
    'numeric': 0.7,  # vitals, measurements
    'text': 0.8,     # diagnosis, history
}

field_type = get_field_type(field_name)
threshold = THRESHOLDS[field_type]

# Ensemble for low confidence
if crf_confidence > threshold:
    return crf_result
elif rule_confidence > 0.8:
    return rule_result
elif position_confidence > 0.9:
    return position_result
else:
    # Combine strategies (voting)
    return ensemble_vote([crf, rule, position])
```

---

## üìù Next Steps (Immediate)

### Step 1: Generate Diverse Training Data ‚è∞ NOW
```bash
# Generate 100 documents with layout variation
cd tools/seeder
python batch_seeder.py --template medical_form_template \
    --generate --count 100 --validate
```

### Step 2: Validate & Correct ‚è∞ THIS WEEK
```
1. Review generated documents
2. Correct any extraction errors
3. Ensure ground truth is accurate
4. Mark as validated
```

### Step 3: Retrain with Full Dataset ‚è∞ THIS WEEK
```bash
# Retrain with all 355 documents (255 + 100)
python tools/retrain_with_field_aware.py --template-id 1
```

### Step 4: Test & Measure ‚è∞ THIS WEEK
```bash
# Test on 50 NEW documents
python batch_seeder.py --template medical_form_template \
    --generate --count 50

# Measure accuracy
# Expected: 60-70% (up from 35%)
```

---

## üéØ Success Criteria

### Short Term (1 week)
- [ ] 100+ diverse documents generated
- [ ] All documents validated & corrected
- [ ] Model retrained with full dataset
- [ ] Accuracy > 60% on new documents

### Medium Term (1 month)
- [ ] New features implemented
- [ ] Text field accuracy > 50%
- [ ] Overall accuracy > 75%
- [ ] Variance < 10% (stable performance)

### Long Term (3 months)
- [ ] Accuracy > 85%
- [ ] Production-ready system
- [ ] Comprehensive documentation
- [ ] Thesis chapter complete

---

## üìö Related Documentation

- `FIELD_AWARE_CRF_SOLUTION.md` - Field-aware implementation
- `CRITICAL_BUG_FIX_FIELD_AWARE_TRAINING.md` - Recent bug fix
- `AUTO_RETRAIN_SAFEGUARDS.md` - Auto-retrain safety
- `AUTO_RETRAIN_THREADING_FIX.md` - Threading issues

---

## ‚úÖ Conclusion

**Current Status:**
- ‚úÖ System architecture: SOLID
- ‚úÖ Field-aware CRF: WORKING
- ‚úÖ Auto-retrain: SAFE & STABLE
- ‚ö†Ô∏è  Accuracy: NEEDS IMPROVEMENT (18-52%)

**Main Issue:**
- Training data lacks diversity
- Model overfits to specific layouts
- Doesn't generalize to new documents

**Solution:**
- Generate MORE diverse training data
- Improve features for generalization
- Optimize strategy selection
- Add post-processing validation

**Confidence:** HIGH that 75-85% accuracy is achievable with these improvements

**Recommendation:** Focus on Priority 1 (Data Diversity) first - biggest impact for least effort!

---

**Status:** üîÑ **IN PROGRESS**  
**Next Action:** **Generate 100+ diverse documents**  
**ETA to 75%:** **1-2 weeks**
